# ğŸ”¥ DekDataset

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![DeepSeek API](https://img.shields.io/badge/DeepSeek-API-FF6B6B?style=for-the-badge&logo=openai&logoColor=white)
![Mistral OCR](https://img.shields.io/badge/Mistral-OCR-4ECDC4?style=for-the-badge&logo=mistral&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-2ECC71?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Production_Ready-27AE60?style=for-the-badge)

</div>

---

<div align="center">
  <h2>ğŸ¯ Advanced AI Dataset Generator for Thai & Multilingual Applications</h2>
  <p><i>Professional-grade synthetic data generation with OCR, NLP, Vision & Multi-modal capabilities</i></p>
  
  <b>âš¡ Fast â€¢ ğŸ¯ Accurate â€¢ ğŸ”§ Extensible â€¢ ğŸ“Š Production-Ready</b>
</div>

---

## ğŸŒŸ Overview

**DekDataset** is a comprehensive open-source framework for generating high-quality AI/ML datasets in Thai and multiple languages. Designed for both research and enterprise applications, it seamlessly integrates OCR document processing, NLP tasks, computer vision, and multi-modal data generation into a unified, scalable platform.

### ğŸ¯ Key Differentiators

- ğŸ” **Advanced OCR Integration**: Extract text from PDFs, images, and documents using Mistral OCR API
- ğŸ§  **AI-Powered Generation**: Leverage DeepSeek LLM for context-aware synthetic data creation  
- ğŸŒ **Thai Language Optimized**: Native support for Thai NLP tasks and cultural context
- ğŸ­ **Enterprise-Ready**: Robust error handling, batch processing, and production deployment features

---

## ğŸ“‘ Table of Contents

- [ğŸŒŸ Overview](#-overview)
- [âœ¨ Features](#-features)  
- [âš¡ Quick Start](#-quick-start)
- [ğŸ” OCR Document Processing](#-ocr-document-processing)
- [ğŸ› ï¸ How It Works](#ï¸-how-it-works)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ–¼ï¸ Example Use Cases](#ï¸-example-use-cases)
- [ğŸ§‘â€ğŸ’» Technical Details](#-technical-details)
- [ğŸ™ Credits & License](#-credits--license)

---

## âœ¨ Features

### ğŸ”§ Core Capabilities

- **ğŸ¯ Unified Task Schema**: Support for NLP, Vision, OCR, and Multi-modal tasks with centralized schema management
- **ğŸ¤– Automatic Prompting**: Generate optimized prompts for LLMs (DeepSeek, OpenAI, etc.) automatically
- **âš¡ Batch Generation**: Advanced batch processing with error recovery, quota management, and intelligent retry mechanisms
- **ğŸ“Š Data Validation & Metadata**: Complete validation, deduplication, enrichment, label balancing, and metadata export
- **ğŸ’¾ Flexible Output**: Export to JSONL, Parquet, Arrow, CSV formats compatible with HuggingFace, PyArrow, and Pandas

### ğŸ” Advanced OCR & Document Processing

- **ğŸ“„ PDF Processing**: Extract text from multi-page PDF documents using Poppler integration
- **ğŸ–¼ï¸ Image OCR**: Process JPG, PNG, JPEG images with high-accuracy text recognition
- **ğŸŒ URL Support**: Direct processing of remote documents and images via URLs
- **ğŸ¯ Context-Aware Generation**: Use extracted OCR text as context for LLM-based dataset creation

### ğŸŒ Web Integration & Media

- **ğŸ” Web Scraping**: Download images from Bing, DuckDuckGo, Pexels, Pixabay with metadata
- **ğŸ¨ AI Image Generation**: Integrated support for AI-generated images and captions
- **ğŸ“± Multi-modal**: Combine text, images, and metadata for comprehensive datasets

### ğŸ›¡ï¸ Enterprise Features

- **ğŸ”’ Robust & Reproducible**: Comprehensive error handling, logging, retry mechanisms, and fallback strategies
- **ğŸ“ˆ Scalable Architecture**: Support for large-scale batch processing and distributed generation
- **ğŸ”§ Extensible Design**: Easy task/schema customization via `tasks.json` or REST API
- **ğŸ“‹ Production Monitoring**: Built-in monitoring, logging, and performance tracking

---

## âš¡ Quick Start

### 1. Installation & Setup

```bash
# Clone repository
git clone https://github.com/yourusername/DekDataset.git
cd DekDataset

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Keys

Create a `.env` file in the project root:

```env
# Required: DeepSeek API for LLM generation
DEEPSEEK_API_KEY=your_deepseek_api_key

# Required: Mistral API for OCR processing
MISTRAL_API_KEY=your_mistral_api_key

# Optional: Image download services
PEXELS_API_KEY=your_pexels_api_key
PIXABAY_API_KEY=your_pixabay_api_key
```

### 3. Basic Dataset Generation

```bash
# Generate NLP dataset
python src/python/generate_dataset.py sentiment_analysis 100 --format jsonl

# Generate dataset from PDF document
python src/python/generate_dataset.py primary_school_knowledge 50 --input-file document.pdf

# Generate with custom settings
python src/python/generate_dataset.py medical_text_summarization 25 --delay 2 --format parquet
```

### 4. Advanced Usage

```bash
# Start task definitions API server
python src/python/task_definitions_api.py

# Export to different formats
python data/output/export_parquet_arrow.py data/output/dataset.jsonl parquet
```

---

## ğŸ” OCR Document Processing

### Supported Formats

- **ğŸ“„ PDF Documents**: Multi-page PDFs with automatic page-by-page processing
- **ğŸ–¼ï¸ Images**: JPG, PNG, JPEG files with high-accuracy text extraction
- **ğŸŒ Remote Files**: Direct URL processing for online documents and images

### OCR Workflow Examples

#### Extract Text Only

```bash
# Extract from local PDF
python src/python/generate_dataset.py --input-file document.pdf

# Extract from image
python src/python/generate_dataset.py --input-file image.png

# Extract from URL
python src/python/generate_dataset.py --input-file https://example.com/document.pdf
```

#### Generate Dataset from Documents

```bash
# Create sentiment analysis dataset from PDF
python src/python/generate_dataset.py sentiment_analysis 20 --input-file textbook.pdf

# Generate medical dataset from research paper
python src/python/generate_dataset.py medical_text_summarization 15 --input-file research_paper.pdf

# Create Q&A dataset from educational content
python src/python/generate_dataset.py primary_school_knowledge 30 --input-file educational_material.png
```

### OCR Technical Features

- **ğŸ”§ Automatic Poppler Integration**: Built-in PDF processing without system dependencies
- **ğŸ¯ High-Accuracy Text Extraction**: Mistral OCR API with advanced text recognition
- **ğŸ“Š Context-Aware Processing**: Extracted text feeds directly into LLM generation pipeline
- **âš¡ Batch Document Processing**: Handle multiple documents and large files efficiently

---

## ğŸ› ï¸ How It Works

### Generation Pipeline

1. **ğŸ“‹ Task Selection**: Choose from predefined tasks or create custom schemas
2. **ğŸ” Document Processing**: (Optional) Extract text from PDFs/images using OCR
3. **ğŸ¤– Prompt Generation**: Automatically generate optimized prompts for LLM
4. **âš¡ Batch Generation**: Create synthetic data in intelligent batches with error recovery
5. **âœ… Validation & Processing**: Validate, deduplicate, enrich, and balance generated data
6. **ğŸ’¾ Export & Metadata**: Export to multiple formats with comprehensive metadata

### Architecture Overview

```mermaid
graph TD
    A[Input Documents/Tasks] --> B[OCR Processing]
    B --> C[Context Extraction]
    C --> D[LLM Prompt Generation]
    D --> E[Batch Generation]
    E --> F[Data Validation]
    F --> G[Export & Metadata]
    G --> H[Multiple Output Formats]
```

---

## ğŸ“ Project Structure

```text
DekDataset/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ¦€ main.rs, models.rs, api_client.rs, generator.rs, banner.rs
â”‚   â””â”€â”€ ğŸ python/
â”‚       â”œâ”€â”€ generate_dataset.py      # Main generation script
â”‚       â”œâ”€â”€ ocr_utils.py            # OCR processing module
â”‚       â”œâ”€â”€ task_definitions.py     # Task schema management
â”‚       â””â”€â”€ task_definitions_api.py # REST API server
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ output/                     # Generated datasets
â”‚   â””â”€â”€ pdf/                        # Sample PDF documents
â”œâ”€â”€ ğŸ“ poppler-local/               # Portable PDF processing
â”œâ”€â”€ ğŸ“ docs/                        # Documentation
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â””â”€â”€ ğŸ“„ README.md                    # This file
```

---

## ğŸ–¼ï¸ Example Use Cases

### 1. Medical AI Dataset Creation

```bash
# Generate comprehensive medical benchmark dataset
python src/python/generate_dataset.py medical_benchmark 1000 --format jsonl --delay 1

# Create medical Q&A from research papers
python src/python/generate_dataset.py medical_text_summarization 200 --input-file medical_research.pdf
```

**Output**: High-quality medical datasets for training AI models, medical Q&A systems, or clinical decision support tools.

### 2. Educational Content Generation

```bash
# Thai primary school knowledge base
python src/python/generate_dataset.py primary_school_knowledge 500 --input-file thai_textbook.pdf

# Generate educational Q&A pairs
python src/python/generate_dataset.py qa_generation 300 --input-file educational_content.pdf
```

**Output**: Educational datasets for Thai language learning applications, automated tutoring systems, and knowledge assessment tools.

### 3. Thai NLP Model Training

```bash
# Sentiment analysis dataset in Thai
python src/python/generate_dataset.py sentiment_analysis 2000 --format parquet

# Text classification for Thai content
python src/python/generate_dataset.py text_classification 1500 --delay 2
```

**Output**: Large-scale Thai language datasets for training sentiment analysis, text classification, and other NLP models.

### 4. Document Processing Automation

```bash
# Process multiple PDF documents
python src/python/generate_dataset.py document_summarization 100 --input-file legal_documents.pdf

# Extract and analyze business reports
python src/python/generate_dataset.py business_analysis 75 --input-file quarterly_report.pdf
```

**Output**: Automated document analysis and summarization datasets for enterprise applications.

---

## ğŸ§‘â€ğŸ’» Technical Details

### Technology Stack

- **ğŸ Python 3.10+**: Core processing and API integration
- **ğŸ¦€ Rust Components**: High-performance data processing modules
- **ğŸ¤– DeepSeek API**: Advanced LLM for synthetic data generation
- **ğŸ” Mistral OCR**: State-of-the-art optical character recognition
- **ğŸ“„ Poppler**: Robust PDF processing and conversion
- **âš¡ FastAPI**: REST API for task management and automation

### Key Components

- **ğŸ”§ OCR Engine**: Mistral API integration with local Poppler support
- **ğŸ“Š Data Pipeline**: Robust batch processing with error recovery
- **ğŸ¯ Task Management**: Flexible schema system with custom task support
- **ğŸ’¾ Export System**: Multi-format output with metadata preservation
- **ğŸ›¡ï¸ Error Handling**: Comprehensive logging and retry mechanisms

### Performance & Scalability

- **âš¡ Batch Processing**: Intelligent batching for optimal API usage
- **ğŸ”„ Error Recovery**: Automatic retry with exponential backoff
- **ğŸ“ˆ Scalable Architecture**: Support for distributed processing
- **ğŸ“Š Monitoring**: Built-in performance tracking and logging

### Integration Capabilities

- **ğŸ¤— HuggingFace**: Direct compatibility with Datasets and Transformers
- **ğŸ“Š PyArrow/Pandas**: Native support for data analysis workflows
- **â˜ï¸ Cloud Deployment**: Docker and cloud-ready architecture
- **ğŸ”Œ API Integration**: RESTful API for external system integration

---

## ğŸ™ Credits & License

### Acknowledgments

- **ğŸ¢ DeepSeek**: Advanced LLM capabilities and API integration
- **ğŸ” Mistral AI**: High-quality OCR processing and text extraction
- **ğŸ¤— HuggingFace**: Ecosystem integration and dataset standards
- **ğŸ“Š Apache Arrow**: High-performance data processing and storage
- **ğŸŒ Open Source Community**: Various libraries and tools that make this project possible

### License & Usage

- **ğŸ“„ License**: MIT License - see [LICENSE](LICENSE) for details
- **ğŸ’¼ Commercial Use**: Permitted under MIT license terms
- **ğŸ”§ Contributions**: Welcome via pull requests and issues
- **ğŸ“ Support**: Community support through GitHub issues

### Project Information

- **ğŸ‘¨â€ğŸ’» Developed by**: ZOMBIT Team
- **ğŸŒ Repository**: [github.com/JonusNattapong/DekDataset](https://github.com/JonusNattapong/DekDataset)
- **ğŸ“§ Contact**: zombitx64@gmail.com
- **ğŸ¯ Version**: 2025.05 - Production Ready
- **ğŸ·ï¸ Tags**: AI, ML, Dataset, Thai NLP, OCR, Synthetic Data, DeepSeek, Python

---

<div align="center">

**â­ Star this repository if you find it useful!**

[![GitHub stars](https://img.shields.io/github/stars/JonusNattapong/DekDataset?style=social)](https://github.com/JonusNattapong/DekDataset/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/JonusNattapong/DekDataset?style=social)](https://github.com/JonusNattapong/DekDataset/network/members)
[![GitHub issues](https://img.shields.io/github/issues/JonusNattapong/DekDataset)](https://github.com/JonusNattapong/DekDataset/issues)

</div>
